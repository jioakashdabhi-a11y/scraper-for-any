name: Amazon Product Scraper

on:
  # Triggered via repository_dispatch from backend
  repository_dispatch:
    types: [trigger_scraper]
  
  # Fallback: Run on schedule (configurable, default every 30 minutes)
  schedule:
    - cron: '*/30 * * * *'
  
  # Manual trigger for testing
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: scraper/package-lock.json
      
      - name: Install dependencies
        working-directory: ./scraper
        run: npm ci
      
      - name: Install Chromium dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libnss3 \
            libatk1.0-0 \
            libatk-bridge2.0-0 \
            libcups2 \
            libdrm2 \
            libxkbcommon0 \
            libxcomposite1 \
            libxdamage1 \
            libxrandr2 \
            libgbm1 \
            libasound2
      
      - name: Run scraper
        working-directory: ./scraper
        env:
          BACKEND_API_URL: ${{ secrets.BACKEND_API_URL }}
          SCRAPER_API_TOKEN: ${{ secrets.SCRAPER_API_TOKEN }}
          PUPPETEER_HEADLESS: true
          PUPPETEER_TIMEOUT: 30000
        run: npm start
      
      - name: Notify on failure
        if: failure()
        run: echo "Scraper failed! Check logs for details."
